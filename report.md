# Unified-OneHead 多任務學習挑戰報告

## 摘要

本報告詳述為達成「Unified-OneHead 多任務學習挑戰」所進行的設計、實驗與分析。此挑戰要求使用**單一共享輸出頭 (Unified-OneHead)**，在嚴格的資源限制下（< 8M 參數，≤ 2小時訓練），依序完成 **語意分割**、**物件偵測**與 **影像分類** 三項任務，並將任一任務的災難性遺忘性能衰退控制在 **5%** 以內。為此，本專案採用 **YOLOv8-n** 作為骨幹，設計了一個極簡的雙層卷積共享頭，並結合 **彈性權重鞏固 (EWC)** 與 **經驗回放 (Replay Buffer)** 兩種策略對抗遺忘。

實驗結果顯示，儘管模型架構與資源效率完全符合規範，但在核心性能指標上，最先學習的語意分割任務在訓練結束後性能下降了 **41.63%**，未能達成挑戰的主要目標。本報告將深入剖析我們的架構選擇、訓練策略的理論依據、對實驗結果的分析，以及對未來改進方向的探討。

---

## 1. 資料前處理 (Data Preprocessing)

根據作業要求，我們使用了 Mini-COCO-Det、Mini-VOC-Seg 和 Imagenette-160 三個資料集。我們首先下載了完整的原始數據，並透過筆記本中的腳本執行了精確的抽樣與前處理流程，以構建符合規格的迷你資料集。

* **數據抽樣**：為確保任務間的公平性，我們為每個任務都抽樣了 **240 張訓練影像和 60 張驗證影像**。
* **影像轉換**：所有輸入影像都被統一處理至 `512x512` 像素並進行標準化。語意分割的標籤遮罩則採用 **最近鄰插值法** 進行縮放，此舉可確保類別索引值在轉換過程中不被破壞，是處理分割標籤時的標準做法。

### Mini-COCO-Det 資料集的類別代理策略

一個值得特別說明的細節是 `Mini-COCO-Det` 資料集的構建方式。由於我們為分類任務設定的 10 個目標概念（如 "fish", "CD player"）並非全部存在於 COCO 2017 的官方類別中，我們採用了一種 **類別代理 (Class Proxy)** 策略。我們為每個目標概念，從 COCO 資料集中挑選出視覺或語義上最相似的類別作為其代理，讓模型能學習到相似的底層特徵。

| 目標概念 | COCO 代理類別 (英) | Category ID | 選擇原因 |
| :--- | :--- | :--- | :--- |
| **fish (魚)** | bird | 15 | COCO 中沒有水生動物；鳥類同樣擁有流線型身體、翅鰭狀結構，在視覺上可扮演「動物小體型」的代表。 |
| **dog (狗)** | dog | 18 | 與需求完全一致，直接使用。 |
| **CD player** | remote | 75 | COCO 亦無音響設備；遙控器 (remote) 有相似的 矩形 + 按鈕 外觀，可學到電子產品的細節紋理。 |
| **chainsaw (電鋸)** | scissors | 44 | COCO 中唯一的「工具」類；具有鋒利金屬刃與手持握把，能捕捉小型五金特徵。 |
| **castle (城堡)** | bench | 14 | COCO 不含獨立建築物；長椅 (bench) 同屬「靜態戶外結構」，材質多為木石，可提供紋理與透視線索。 |
| **French horn** | keyboard | 74 | COCO 無樂器類別；鍵盤同屬「複雜曲線／按鍵排列」的細節密集物件，對判別細長金屬件有幫助。 |
| **garbage truck** | truck | 8 | 「卡車」是類型最接近垃圾車的類別；共享大型箱體 + 車輪幾何外觀。 |
| **gas pump machine** | parking meter | 20 | COCO 唯一「路邊立式機器」；其高度、豎立姿態類似加油機。 |
| **golf ball** | sports ball | 37 | sports ball 類別會涵蓋各種圓球，特徵匹配度最高。 |
| **parachute (降落傘)** | kite | 38 | kite 與 parachute 均為薄布展開、連接繩線的高空物體，輪廓形狀與材質相近。 |

---

## 2. 模型架構與資源效率

### 2.1 設計理念與動機

我們的架構設計核心是在滿足嚴格限制的前提下，探索一個簡潔而合理的解決方案。

* **骨幹網路 (Backbone)**：我們選擇了 **YOLOv8-Nano (YOLOv8-n) 的骨幹網路**。
    * **合理性 (Soundness)**：YOLOv8-n 的骨幹網路（約 3.2M 參數）在輕量級和特徵提取能力之間取得了絕佳平衡。其在 ImageNet 上的預訓練權重為下游任務提供了豐富的底層特徵，這是多任務學習成功的基石。
    * **創意性 (Creativity)**：選擇 YOLOv8-n 而非其他模型，是因為其現代化的結構（如 C2f 模塊）在計算效率上具有優勢，能讓我們將更多參數和計算資源預算留給潛在更複雜的頭部設計。

* **統一頭部 (Unified Head)**：
    * **架構**：我們設計了一個由兩層 `3x3` 卷積層組成的共享頭部。這是一個刻意為之的極簡設計，直接將骨幹的輸出特徵圖進行處理，形成一個對所有任務都必須使用的「資訊瓶頸」。
    * **合理性與動機**：此設計的合理性在於，它強迫模型學習一個高度抽象且通用的特徵表示。理論上，一個足夠泛化的表示應該能同時服務於像素級（分割）、物件級（偵測）和影像級（分類）的任務。這也是對「單一分支」要求的直接回應，考驗模型在最少的分支下能達到的性能極限。

### 2.2 資源效率分析

本方案在設計時已將資源效率作為核心考量，完全符合評分要求。

* **模型參數**：模型的總參數約為 **420 萬**，完全符合 **小於 800 萬 (< 8M) 參數** 的要求。詳細計算如下表所示：

| 組件 (Component) | 輸出維度 (Output Shape) | 參數計算公式 | 參數數量 |
| :--- | :--- | :--- | :--- |
| **Backbone (YOLOv8-n)** | `(B, 256, 16, 16)` | (來自 yolov8n.pt 模型的前10層) | ~3,011,264 |
| **Unified Head: Conv1** | `(B, 256, 16, 16)` | `(256 * 256 * 3 * 3) + 256` | 590,080 |
| **Unified Head: Conv2** | `(B, 256, 16, 16)` | `(256 * 256 * 3 * 3) + 256` | 590,080 |
| **Seg Output: Conv** | `(B, 21, 16, 16)` | `(256 * 21 * 1 * 1) + 21` | 5,397 |
| **Det Output: Conv** | `(B, 15, 16, 16)` | `(256 * 15 * 1 * 1) + 15` | 3,855 |
| **Cls Output: Linear** | `(B, 10)` | `(256 * 10) + 10` | 2,570 |
| **總計 (Total)** | - | **各組件加總** | **~4,203,246** |

* **訓練時間**：本次實驗的總訓練時長為 **23 分 21 秒**，在 NVIDIA RTX 4060 laptop 環境下完成。
---

## 3. 訓練策略與災難性遺忘緩解

### 3.1. 訓練排程
我們完整地實作了作業規定的三階段順序訓練法：
1.  **階段一：專注於分割任務**
2.  **階段二：專注於偵測任務**
3.  **階段三：專注於分類任務**

### 3.2. 災難性遺忘緩解策略
在本次挑戰中，模型被要求依序學習三個性質迥異的任務，這會引發經典的**災難性遺忘 (Catastrophic Forgetting)**問題。為此，我們選擇了結合**彈性權重鞏固 (EWC)** 和 **經驗回放 (Replay Buffer)** 的混合策略。
#### 彈性權重鞏固 (EWC) 實作細節
EWC 的核心是識別並保護對已學習任務「重要」的權重。
* **理論核心**：我們使用 **費雪資訊矩陣 (Fisher Information Matrix)** 來量化每個權重的重要性。費雪資訊衡量的是，如果一個權重發生微小變化，模型的輸出會有大多大的改變。對舊任務影響越大的權重，其費雪資訊值就越高，也就越「重要」。
* **本專案的流程**：
    1.  **訓練完分割任務後**：我們調用 `ewc.update(train_loaders['seg'])`，遍歷一次分割任務的訓練集，計算出每個權重對於分割任務的費雪資訊值，並將當時的模型權重視為 $\theta^*_{Seg}$ 保存下來。
    2.  **訓練偵測任務時**：損失函數變為 $L_{Det} + \lambda \sum F_{Seg}(\theta - \theta^*_{Seg})^2$。這意味著，模型在學習偵測的同時，如果試圖大幅改變對分割很重要的權重，就會受到很大的懲罰。
    3.  **訓練完偵測任務後**：我們再次調用 `ewc.update(train_loaders['det'])`。此時，EWC 模塊會累加新的費雪資訊，即 $F_{new} = F_{Seg} + F_{Det}$，並將此時的權重視為 $\theta^*_{Det}$。
    4.  **訓練分類任務時**：損失函數會同時保護前兩個任務的知識。

#### 分層經驗回放 (Stratified Replay Buffer) 實作細節
Replay Buffer 的核心是透過「溫故知新」來鞏固記憶。
* **理論核心**：透過在訓練新任務時穿插舊任務的真實樣本，模型的神經網路激活路徑會被重新導向，從而加固與舊任務相關的權重，防止其因學習新任務而被完全覆蓋。
* **本專案的流程**：
    1.  **樣本儲存**：在訓練每個任務的第一個 epoch，我們會從數據中抽取 10 個樣本存入 Replay Buffer 中。
    2.  **分層抽樣**：特別對於分類任務，我們採用了**分層抽樣**，確保緩衝區中的 10 個樣本盡可能來自不同的類別，這比純隨機抽樣更能代表數據的整體分佈。
    3.  **回放訓練**：在訓練新任務時（例如階段二的偵測任務），每個 epoch 的常規訓練結束後，我們會從 Replay Buffer 中取出屬於舊任務（分割）的樣本，組成一個小的 batch，再對模型進行一次額外的訓練步驟。這個步驟的損失函數會根據樣本的任務 ID 動態切換，確保模型用正確的方式「複習」舊知識。

---

## 4. 實驗結果與性能分析

### 4.1. 核心性能指標

| Metric | Baseline (訓練後) | After Det Training | After Cls Training (最終) | % Drop vs. Baseline | % Final Drop vs. Baseline |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Seg mIoU** | 14.93% | 13.62% | 8.72% | 8.78% | **41.63%** |
| **Det mAP** | — | 0.22% | 1.40% | — | -536.36% |
| **Cls Top-1 Acc**| — | — | 41.67% | — | — |

### 4.2. 性能分析

* **核心標準評估**：實驗結果中最關鍵的一點是，**模型未能達成「所有任務性能下降 ≤ 5%」的核心要求**。語意分割 (mIoU) 的性能在最終階段下降了 **41.63%**，這是一個顯著的失敗。因此，我們也未能獲得「所有指標不降反升」的 5 分額外獎勵。

* **遺忘分析**：
    * **分割任務的嚴重遺忘**：最先學習的分割任務受創最重。這可能是因為像素級的分割任務需要模型記住大量低階和中階的空間特徵細節。當後續的偵測和分類任務（更注重抽象語義特徵）被訓練時，模型共享的權重被迫向更抽象的特徵空間遷移，從而「覆蓋」了對分割至關重要的空間細節知識。
    * **偵測與分類的意外增益**：Det mAP 和 Cls Acc 的反常提升，可能說明 EWC 和 Replay 策略起到了意想不到的「正則化」作用。持續的、多樣化的數據輸入可能幫助模型跳出了在單一迷你資料集上訓練時可能陷入的局部最優點，從而提升了泛化能力。然而，這項增益是建立在犧牲分割任務性能的基礎之上的。

---

## 5. 結論與未來展望

本專案圍繞一個統一共享頭部的多任務模型，系統性地實現了作業所要求的架構與訓練流程，並應用了 EWC 和 Replay Buffer 作為持續學習策略。我們的模型設計在參數和效率上完全達標。

然而，在最關鍵的性能指標上，我們未能成功抑制災難性遺忘，尤其是在語意分割任務上。這揭示了在任務差異性極大（像素級 vs. 物件級 vs. 影像級）時，單純依賴極簡共享頭部和標準持續學習方法的局限性。

基於本次實驗的經驗，未來的工作可以朝以下方向改進：
1.  **探索更先進的共享頭部**：根據 FAQ 的提示，可以將共享頭部替換為一個小型的 Transformer，利用其自註意力機制動態地為不同任務聚焦於特徵圖的不同區域。
2.  **改善遺忘緩解策略**：增大 Replay Buffer 的容量，並對 EWC 的懲罰權重 $\lambda$ 進行更細緻的超參數搜索。
3.  **任務親和度分組**：考慮將架構微調，例如讓較為接近的任務（如偵測和分割）共享更多底層權重，而與分類任務的共享程度稍低。

